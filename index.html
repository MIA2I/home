
<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<title>MIAMI Group</title>

<link rel="stylesheet" href="css/bootstrap.min.css">

<!-- Main css -->
<link rel="stylesheet" href="css/style.css">
<link href="https://fonts.googleapis.com/css?family=Lora|Merriweather:300,400" rel="stylesheet">

</head>
<body>

<!-- Navigation section  -->

<div class="navbar navbar-default navbar-static-top" role="navigation">
     <div class="container">

          <div class="navbar-header">
               <button class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon icon-bar"></span>
                    <span class="icon icon-bar"></span>
                    <span class="icon icon-bar"></span>
				</button>
				<p><a href="index.html" class="navbar-brand">MIAMI Group</a></p> <!--<div align="center"><a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3214637&c=9644224" alt="AmazingCounters.com"></a></div> </a>-->
		  </div>
          <div class="collapse navbar-collapse">
               <ul class="nav navbar-nav navbar-right">
                    <li><a href="#Bio">Bio</a></li>
					<li><a href="#News">News</a></li>
                    <!-- <li><a href="#Experience">Experience</a></li> -->
					<li><a href="#Award">Award</a></li>
                    <li><a href="#Publication">Publication</a></li>
               </ul>
          </div>
		  <p><font color="red">M</font>edical <font color="red">I</font>mage <font color="red">A</font>nalysis via <font color="red">M</font>achine <font color="red">I</font>ntelligence</p>

  </div>
</div>

<!-- Bio Section -->
<section id="Title">
     <div class="container">
		    <h3>  </h3>
		    <div class="row">
		    <div class="col-md-offset-1 col-md-20 col-sm-20">
                    <div class="col-md-3 col-sm-6">
                         <img class="img-circle" src="images/MICS.jpg" class="img-responsive" alt="" style="width:220px;height:220px;">
                    </div>
					
                    <div class="col-md-9 col-sm-6">
                        <h3>Zengqiang (John) Yan</h3>
			<div style="text-align:justify">
				<p>Ph.D. HKUST</p>
				<p> </p>
				<p>Associate Professor</p>
				<p>School of Electronic Information and Communications, Huazhong University of Science and Technology</p>
				<p>Email: zyanad [at] connect (dot) ust (dot) hk OR z_yan [at] hust [dot] edu [dot] cn </p>
			</div>
                    </div>
                    <div class="clearfix"></div>
               </div>
          </div>
     </div>
</section>

<!-- Bio Section -->
<section id="Bio">
     <div class="container" style="text-align:justify">
		<h3>Bio</h3>
		<p>
			I am an Associate Professor of School of Electronic Information and Communications at Huazhong University of Science and Technology. Before joining HUST, I received my Ph.D. degree  and completed a one-year post-doc both at the <a href="http://www.cse.ust.hk/">Department of Computer Science and Engineering</a> 
			at the <a href="http://www.ust.hk/">Hong Kong University of Science and Technology</a>, supervised by <a href="https://facultyprofiles.ust.hk/profiles.php?profile=tim-kwangting-cheng-timcheng">Prof. Kwang-Ting Tim Cheng</a>. 
		</p>
		<p>
			My research interests include deep learning and medical image analysis, with specific focus on medical image segmentation, domain adaptation and federated learning. The main motivation is to develop annotation-effecient deep learning approaches to tackle medical imaging problems.
		</p>
		<p><b><font color="red">
			<font color="#0080FF">研究兴趣：人工智能、医学图像处理、计算机视觉</font>
		</font></b></p>
		<p>
			Looking for self-motivated undergraduate/postgraduate students to join my group. Feel free to contact me if you have interests.
		</p>
		<p><b>
			<font color="#0080FF">欢迎本科生、保研生、直博生或计划出国（境）读博的同学加入我们团队。</font><font color="red">招2024级硕士研究生2名，欢迎2020级本科保研同学尽早联系进组。</font>
		</b></p>
     </div>
</section>

<section id="News">
	<div class="container" style="text-align:justify">
		<h3 class="section-title">News</h3>
		<div class="row">
			<div class="col-md-4">
				<div class="boxed-news">
		 			<h3><b>AAAI</b></h3>
					<p>Dec. 2023</p>
					<p>Zhehao's paper, entitled "<b>DTMFormer: Dynamic Token Merging for Boosting Transformer-based Medical Image Segmentation</b>", has been accepted by <i>AAAI 2024</i>. Congratulations!</p>
				</div>
			</div>
			<div class="col-md-4">
				<div class="boxed-news">
		 			<h3><b>AAAI</b></h3>
					<p>Dec. 2023</p>
					<p>Nannan's paper, entitled "<b>FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image Segmentation Against Heterogeneous Annotation Noise</b>", has been accepted by <i>AAAI 2024</i>. Congratulations!</p>
				</div>
			</div>
			<div class="col-md-4">
				<div class="boxed-news">
		 			<h3><b>IEEE JBHI</b></h3>
					<p>Oct. 2023</p>
					<p>Junjie's paper, entitled "<b>M2FTrans: Modality-Masked Fusion Transformer for Incomplete Multi-Modality Brain Tumor Segmentation</b>", has been accepted by <i>IEEE Journal of Biomedical  and Health Informatics (IEEE JBHI)</i>. Congratulations!</p>
				</div>
			</div>
		 </div>
</div>
</section>


<!-- Award Section -->
<section id="Award">
     <div class="container" style="text-align:justify">
		<h3 class="section-title">Award</h3>
	     	<p>IEEE TMI Distinguished Reviewer Gold Level 2022-2023</p>
		<p>HKUST Postgraduate Scholarship (2016-2020)</p>
                <p><b>Top 10% Paper Award</b>, IEEE International Workshop on Multimedia Signal Processing 2015</p>
		<p><b>Student Travel Grant Award</b>, IEEE Signal Processing Society 2015</p>
     </div>
</section>

<!-- Publication Section -->
<section id="Publication">
     <div class="container" style="text-align:justify">
		<h3>Selected Publication [<a href="https://scholar.google.com.hk/citations?user=j0-TqGAAAAAJ&hl=zh-CN">Google Scholar</a>]</h3>
		<p>[# Co-First Author * Corresponding Author]</p>
		<h3>@HUST 2022-now</h3>
	        <h3><b>2023</b></h3>
		</p>
	        <p>
			DTMFormer: Dynamic Token Merging for Boosting Transformer-based Medical Image Segmentation<br>
			Zhehao Wang, Xian Lin, Nannan Wu, Li Yu, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b><br>
			<i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2024.
		</p>
	        <p>
			FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image Segmentation Against Heterogeneous Annotation Noise<br>
			Nannan Wu, Zhaobin Sun, <b>Zengqiang Yan*</b>, and Li Yu<br>
			<i>AAAI Conference on Artificial Intelligence (AAAI)</i>, 2024.
		</p>
	        <p>
			FedIOD: Federated Multi-Organ Segmentation from Partial Labels by Exploring Inter-Organ Dependency<br>
			Qin Wan#, <b>Zengqiang Yan</b>#, and Li Yu<br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2023. (under MAJOR REVISION)
		</p>
	        <p>
			M2FTrans: Modality-Masked Fusion Transformer for Incomplete Multi-Modality Brain Tumor Segmentation<br>
			Junjie Shi, Li Yu, Qimin Cheng, Xin Yang, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b><br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2023. accepted
		</p>
	        <p>
			ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation<br>
			Xian Lin, <b>Zengqiang Yan*</b>, Xianbo Deng, Chuansheng Zheng, and Li Yu<br>
			<i>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2023.
		</p>
	        <p>
			FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification<br>
			Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b><br>
			<i>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2023. (Early Accept)
		</p>
	        <p>
			Affinity Feature Strengthening for Accurate, Complete and Robust Vessel Segmentation<br>
			Tianyi Shi, Xiaohuan Ding, Wei Zhou, Feng Pan, <b>Zengqiang Yan</b>, Xiang Bai, and Xin Yang<br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2023. accepted
		</p>
		<p>
			FedNoRo: Towards Noise-Robust Federated Learning By Addressing Class Imbalance and Label Noise Heterogeneity<br>
			Nannan Wu, Li Yu, Xuefeng Jiang, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b><br>
			<i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2023.
		</p>
	        <p>
			Cluster-Re-Supervision: Bridging the Gap Between Image-Level and Pixel-Wise Labels for Weakly Supervised Medical Image Segmentation<br>
			Zhuo Kuang, <b>Zengqiang Yan*</b>, Huiyu Zhou, and Li Yu*<br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2023. accepted
		</p>
		<h3><b>2022</b></h3>
		<p>
			BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation<br>
			Xian Lin, Li Yu, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b> <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2022. accepted
		</p>
	        <p>
			The Lighter The Better: Rethinking Transformers in Medical Image Segmentation Through Adaptive Pruning<br>
			Xian Lin, Li Yu, Kwang-Ting Cheng, and <b>Zengqiang Yan*</b> <br>
			<i>IEEE Transactions on Medical Imaging (IEEE TMI)</i>, 2022. accepted
		</p>
		<p>
			FedMix: Mixed Supervised Federated Learning for Medical Image Segmentation <br>
			Jeffry Wicaksana, <b>Zengqiang Yan*</b>, Dong Zhang, Xijie Huang, Huimin Wu, Xin Yang, and Kwang-Ting Cheng <br>
			<i>IEEE Transactions on Medical Imaging (IEEE TMI)</i>, 2022. accepted
		</p>
	     	<p>
			Hierarchical Associative Encoding and Decoding for BottomUp Human Pose Estimation <br>
			Congju Du, <b>Zengqiang Yan</b>, Han Yu, Li Yu, and Zixiang Xiong <br>
			<i>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</i>, 2022. to appear
		</p>
		<p>
			Customized Federated Learning for Multi-Source Decentralized Medical Image Classification <br>
			Jeffry Wicaksana, <b>Zengqiang Yan*</b>, Xin Yang, Yang Liu, Lixin Fan, Kwang-Ting Cheng <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2022. to appear
		</p>
		<p>
			Symmetry-Aware Deep Learning for Cerebral Ventricle Segmentation with Intra-Ventricular Hemorrhage <br>
			Yineng Hua#, <b>Zengqiang Yan</b>#, Zhuo Kuang, Hang Zhang, Xianbo Deng, Li Yu <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, 2022. online published
		</p>
		<p>
			Fracture R-CNN: An Anchor-Efficient Anti-Interference Framework for Skull Fracture Detection in CT Images <br>
			Xian Lin#, <b>Zengqiang Yan</b>#, Zhuo Kuang, Hang Zhang, Xianbo Deng, Li Yu <br>
			<i>Medical Physics</i>, 2022. online published
		</p>
		<p>
			Uncertainty-Aware Deep Learning with Cross-Task Supervision for PHE Segmentation on CT Images <br>
			Zhuo Kuang#, <b>Zengqiang Yan</b>#, Li Yu, Xianbo Deng, Yineng Hua, Shuyun Li <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, vol. 26, no. 6, pp. 2615-2626, 2022.
		</p>

	<h3>@HKUST 2016-2021</h3>

		<p>
			<a href="pdf/jbhi2020.pdf">
				Variation-Aware Federated Learning with Multi-Source Decentralized Medical Image Data
			</a><br>
			<b>Zengqiang Yan</b>, Jeffry Wicaksana, Zhiwei Wang, Xin Yang, Kwang-Ting Cheng <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, vol. 25, no. 7, pp. 2615-2628, 2021.
		</p>
		<p>
			<a href="pdf/tmi2020.pdf">
				Enabling a Single Deep Learning Model for Accurate Gland Instance Segmentation: A Shape-aware Adversarial Learning Framework
			</a><br>
			<b>Zengqiang Yan</b>, Xin Yang, Kwang-Ting Cheng <br>
			<i>IEEE Transactions on Medical Imaging (IEEE TMI)</i>, vol. 39, no. 6, pp. 2176-2189, Jun. 2020.
		</p>
		<p>
			<a href="pdf/jbhi2018.pdf">
				A Three-stage Deep Learning Model for Accurate Retinal Vessel Segmentation
			</a><br>
			<b>Zengqiang Yan</b>, Xin Yang, Kwang-Ting Cheng <br>
			<i>IEEE Journal of Biomedical and Health Informatics (IEEE JBHI)</i>, vol. 23, no. 4, pp. 1427-1436, Jul. 2019.
			<font color="red"><b>ESI Highly Cited Paper</b></font>
		</p>
		<p>
			<a href="pdf/tbme2018.pdf">
				Joint Segment-level and Pixel-wise Losses for Deep Learning based Retinal Vessel Segmentation
			</a><br>
			<b>Zengqiang Yan</b>, Xin Yang, Kwang-Ting Cheng <br>
			<i>IEEE Transactions on Biomedical Engineering (IEEE TBME)</i>, vol. 65, no. 9, pp. 1912-1923, Sept. 2018.
			[<a href="https://github.com/ZengqiangYan/Joint-Segment-level-and-Pixel-wise-Losses-for-Deep-Learning-based-Retinal-Vessel-Segmentation">
				Github
				</a>]
			<font color="red"><b>ESI Highly Cited Paper</b></font>
		</p>
		<p>
			<a href="pdf/tmi2017.pdf">
				A Skeletal Similarity Metric for Quality Evaluation of Vessel Segmentation
			</a><br>
			<b>Zengqiang Yan</b>, Xin Yang, Kwang-Ting Cheng <br>
			<i>IEEE Transactions on Medical Imaging (IEEE TMI)</i>, vol. 37, no. 4, pp. 1045-1057, Apr. 2018.
			[<a href="https://github.com/ZengqiangYan/SkeletalSimilarityMetric">
				Github
				</a>]
		</p>
		<p>
			<a href="pdf/miccai2018.pdf">
				A Deep Model with Shape-preserving Loss for Gland Instance Segmentation
			</a><br>
			<b>Zengqiang Yan</b>, Xin Yang, Kwang-Ting Cheng <br>
			<i>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2018, pp. 138-146.
		</p>
		<p>
			Exploring Intermediate Representation for Monocular Vehicle Pose Estimation<br>
			Shichao Li, <b>Zengqiang Yan</b>, Hongyang Li, Kwang-Ting Cheng <br>
			<i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2021.
		</p>
     </div>
</section>

<!-- External Section -->
<section id="External">
     <div class="container" style="text-align:justify">
		<h3>External Links</h3>
                <a href="http://vsdl.ust.hk/">HKUST Vision and System Design Lab, </a>
		<a href="http://dblp.uni-trier.de/pers/hd/y/Yan:Zengqiang">DBLP, </a>
		<a href="https://www.linkedin.com/in/zengqiang-yan-4b5334100/">LinkedIn, </a>
		<a href="https://scholar.google.com.hk/citations?user=j0-TqGAAAAAJ&hl=zh-CN">Google Scholar, </a>
     </div>
</section>

<section id="Visitor">
     <div class="container"  align="center">
		<a href='https://clustrmaps.com/site/1bhqo'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=488&t=tt&d=hIgWEUABMUmEVns3EE9T4V62WbAYbwbtLtmPJLv6-iI&co=6fb6e9'/></a>
     		<hr>
     </div>
</section>

</body>
</html>
